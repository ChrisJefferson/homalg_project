<?xml version="1.0" encoding="UTF-8"?>

<!-- $Id: manual.xml,  2008/07/01 -->

<!DOCTYPE Book SYSTEM "gapdoc.dtd"
 [ <!ENTITY see '<Alt Only="LaTeX">$\to$</Alt><Alt Not="LaTeX">--&gt;</Alt>'>
   <!ENTITY Gauss "<Package>Gauss</Package>">
   <!ENTITY GaussForHomalg "<Package>GaussForHomalg</Package>">
   <!ENTITY homalg "<Package>homalg</Package>">
   <!ENTITY RingsForHomalg "<Package>RingsForHomalg</Package>">
   <!ENTITY SCO "<Package>SCO</Package>">
 ]>

<Book Name="Gauss">

<TitlePage>
  <Title> The &Gauss; Package Manual</Title>
  <Subtitle>Extended Gauss Functionality for &GAP;</Subtitle>
  <Version>Version 2008.07.01</Version>
  <Author>Simon Goertzen
          <Email>Simon.Goertzen@RWTH-Aachen.De</Email> 
  </Author>
  <Date>July 2008</Date>
  <Address>
  Lehrstuhl B für Mathematik<Br/> Templergraben 
  64<Br/> 52062 Aachen<Br/> (Germany)
  </Address>
  <Abstract>This document explains the primary uses of the &Gauss; package.
            The first introductory chapter answers the question why
            and how the &GAP; functionality concerning a sparse matrix
            type and gaussian algorithms was extended.
            The following chapters are concerned with the workings of
            the sparse matrix type and sparse Gaussian algorithms.
            Included is a documented list of the most important methods
            and functions needed to work with sparse matrices and the
            algorithms provided by the &Gauss; package.
            Anyone interested in source code should just check out the files
            in the <F>gap/pkg/Gauss/gap</F> folder.
  </Abstract>
  <Copyright>&copyright; 2007-2008 by Simon Goertzen
  </Copyright>
  <Acknowledgements>The &Gauss; package would not have been possible without the helpful contributions by
   <List>
    <Item>Dr. Max Neunhoeffer, University of St Andrews, and</Item>
    <Item>Dr. Mohamed Barakat, Lehrstuhl B für Mathematik, RWTH Aachen.</Item>
   </List>
   Many thanks to these two and the Lehrstuhl B für Mathematik in general.
   Last but not least it should be noted that the &GAP; algorithms for
   <C>SemiEchelonForm</C> and other methods formed an important and
   informative basis for the development of the extended Gaussian algorithms.
  </Acknowledgements>
</TitlePage>

<TableOfContents/>

<Body>

<Chapter Label="chap:EGF"><Heading>Extending Gauss Functionality</Heading>

 <Section Label="sec:need"><Heading>The need for extended functionality</Heading>

    &GAP; has a lot of functionality for row echelon forms of
    matrices. These can be called by <C>SemiEchelonForm</C> and
    similar commands. All of these work for the &GAP; matrix type over
    fields. However, these algorithms are not capable of computing a
    reduced row echelon form (RREF) of a matrix, there is no way to
    "Gauss upwards". While this is not neccessary for things like Rank
    or Kernel computations, this was one in a number of missing features
    important for the development of the &homalg; package by
    Dr. Barakat (citation).<P/><P/>
    
    Parallel to this development I worked on &SCO;, a package for
    creating simplicial sets and computing the cohomology of
    orbifolds, based on the paper "Simplicial Cohomology of Orbifolds"
    by Moerdijk (citation). Very early on it became clear that the
    cohomology matrices (with entries in &ZZ; or finite quotients of
    &ZZ;) would grow exponentially in size with the cohomology
    degree. For example, to compute the cohomology of degree 3 of the
    orbifold corresponding to the Wallpaper Group <URL Text="p31m">http://en.wikipedia.org/wiki/Wallpaper_group#Group_p31m</URL>
    a 50651 x 1133693 matrix has to be handled.<P/><P/>
    
    It should be quite clear that there was a need for a sparse matrix
    data type and corresponding Gaussian algorithms. After an
    unfruitful search for a computer algebra system capable of this
    task, the &Gauss; package was born - to provide not only the
    missing RREF algorithms, but also support a new data type,
    enabling &GAP; to handle sparse matrices of almost arbritrary
    size.<P/><P/>
    
    I am proud to tell you that, thanks to optimizing the algorithms
    for matrices over GF(2), it is now possible to compute the
    GF(2)-Rank of the mentioned matrix in less than 20 minutes with a
    memory usage of about 3 GB.
    
 </Section>

 <Section Label="sec:app"><Heading>The applications of the &Gauss; package algorithms</Heading>
    
    Please visit (url?) to find out more about the &homalg; project
    and its related packages. Most of the motivation for the
    algorithms in the &Gauss; package can be found there. If you are
    interested in this project, you might also want to check out my
    &GaussForHomalg; (url) package, which, just as &RingsForHomalg; (url)
    does for external Rings, serves as the connection between &homalg;
    and &Gauss;. By allowing &homalg; to delegate computational tasks to
    &Gauss; this small package extends &homalg;'s  capabilities to
    dense and sparse matrices over fields and rings of the form
    <M>&ZZ; / &lt; p^n ></M>.<P/>
    
    For those unfamiliar with the &homalg; project let me explain a
    couple of points. As outlined in the paper "homalg..." by
    Dr. Daniel Robertz and Dr. Barakat (cit) homological computations
    can be reduced to three basic tasks:<P/>

    <List>
     <Item>Computing a row basis of a module (BasisOfRowModule).</Item>
     <Item>Reducing a module with a basis (DecideZeroRows).</Item>
     <Item>Compute the relations between module elements (SyzygiesGeneratorsOfRows).</Item>
    </List>
    
    In addition to these tasks only relatively easy tools for matrix
    manipulation are needed, ranging from addition and multiplication
    to finding the zero rows in a matrix. However, to reduce the need for
    communication it might be helpful to supply &homalg; with some
    more advanced procedures.<P/><P/>
    
    While the above tasks can be quite difficult when, for example,
    working in noncommutative polynomial rings, in the &Gauss; case
    they can all be done as long as you can compute a Reduced Row
    Echelon Form. This is clear for BasisOfRowModule, as the rows of
    the RREF of the matrix are already a basis of the module. <Ref
    Meth="EchelonMat"/> is used to compute RREFs, based on the &GAP;
    internal method <C>SemiEchelonMat</C> for Row Echelon Forms.<P/><P/>
    
    Lets look at the second point, the basic function DecideZeroRows:
    When you face the task of reducing a module <M>A</M> with a given
    basis <M>B</M>, you can compute the RREF of the following block
    matrix:
    <Table Align="|c|c|">
     <HorLine/>
     <Row>
      <Item><Alt Not="LaTeX">Id</Alt>
            <Alt Only="LaTeX"><![CDATA[
                    \begin{array}{ccc}
                    1&\\
                    &\ddots&\\
                    &&1\\
                    \end{array}
            ]]></Alt></Item>
      <Item>A</Item>
     </Row>
     <HorLine/>
     <Row>
      <Item>0</Item>
      <Item>B</Item>
     </Row>
     <HorLine/>
    </Table>
    By computing the RREF (notice how important "Gaussing upwards" is
    here) <M>A</M> is reduced with <M>B</M>. However, the left side of
    the matrix just serves the single purpose of tricking the Gaussian
    algorithms into doing what we want. Therefore, it was a logical
    step to implement <Ref Meth="ReduceMat"/>, which does the same
    thing but without needing unneccessary columns.<P/><P/>
    
    The third point, SygygiesGeneratorsOfRows, is concerned with the
    relations between rows of a matrix, each row representing a module
    element. Over a field these relations are exactly the kernel of
    the matrix. One can easily see that this can be achieved by taking
    a matrix
    <Table Align="|c|c|">
     <HorLine/>
     <Row>
      <Item>A</Item>
      <Item><Alt Not="LaTeX">Id</Alt>
            <Alt Only="LaTeX"><![CDATA[
                    \begin{array}{ccc}
                    1&\\
                    &\ddots&\\
                    &&1\\
                    \end{array}
            ]]></Alt></Item>
     </Row>
     <HorLine/>
    </Table>
    and computing its Row Echelon Form. Then the row relations are
    generated by the rows to the right of the zero rows of the
    REF. There are two problems with this approach: The computation
    diagonalizes the  kernel, which might not be wanted, and, much
    worse, it does not work at all for rings with zero divisors. For
    example, the <M>1 \times 1</M> matrix <M>[2 + 8&ZZ;]</M> has a row
    relation <M>[4 + 8&ZZ;]</M> which would not have been found by
    this method.<P/>
    
    Approaching this problem led to the method <Ref
    Meth="EchelonMatTransformation"/>, which computes the
    transformation matrix <M>T</M>, such that <M>RREF = T \cdot M</M>,
    in addition to the RREF. Similar to
    <C>SemiEchelonMatTransformation</C>, <M>T</M> is split up into the
    rows needed to create the basis vectors of the RREF, and the
    relations that led to zero rows. Focussing on the computations
    over fields, it was an easy step to write <Ref Meth="KernelMat"/>,
    which terminates after the REF and returns the kernel
    generators.<P/>
    
    
    
 </Section>

</Chapter>

<Chapter Label="chap:SM"><Heading>The Sparse Matrix Data Type</Heading>

 <Section Label="sec:theory"><Heading>The inner workings of &Gauss; sparse matrices</Heading>

 <Subsection Label="sub:gf2"><Heading>A special case: GF(2)</Heading>
 </Subsection>

 </Section>

 <Section Label="sec:mfSM"><Heading>Methods and functions for sparse matrices</Heading>
     <#Include Label="SparseMatrix">
     <#Include Label="ConvertSparseMatrixToMatrix">
     <#Include Label="CopyMat">
     <#Include Label="GetEntry">
     <#Include Label="AddEntry">
     <#Include Label="SparseZeroMatrix">
     <#Include Label="SparseIdentityMatrix">
     <#Include Label="TransposedSparseMat">
     <#Include Label="CertainRows">
     <#Include Label="CertainColumns">
     <#Include Label="UnionOfRows">
     <#Include Label="UnionOfColumns">
     <#Include Label="SparseDiagMat">
     <#Include Label="nrows">
     <#Include Label="ncols">
     <#Include Label="indices">
     <#Include Label="entries">
     <#Include Label="ring">
 </Section>

</Chapter>

<Chapter Label="chap:Gauss"><Heading>Gaussian Algorithms</Heading>

 <Section Label="sec:list"><Heading>A list of the available algorithms</Heading>
 </Section>

 <Section Label="sec:mfGauss"><Heading>Methods and Functions for &Gauss;ian algorithms</Heading>
     <#Include Label="EchelonMat">
     <#Include Label="EchelonMatTransformation">
     <#Include Label="ReduceMat">
     <#Include Label="ReduceMatTransformation">
     <#Include Label="KernelMat">
     <#Include Label="Rank">
 </Section>


</Chapter>

</Body>

<Appendix Label="FileOverview">
<Heading>An Overview of the &Gauss; package source code</Heading>
<Table Align="l|l">
<Caption><E>The &Gauss; package files.</E></Caption>
<Row><Item>Filename</Item><Item>Content</Item></Row>
<HorLine/>
<Row><Item>SparseMatrix.gi</Item><Item>Definitions and methods for
the sparse matrix type</Item></Row>
<Row><Item>SparseMatrixGF2.gi</Item><Item>Special case GF(2): no
matrix entries needed</Item></Row>
<Row><Item>GaussDense.gi</Item><Item>Gaussian elmination for &GAP;
matrices over fields</Item></Row>
<Row><Item>Sparse.gi</Item><Item>Documentation and forking depending
on the base ring</Item></Row>
<Row><Item>GaussSparse.gi</Item><Item>Gaussian elimination for sparse
matrices over fields</Item></Row>
<Row><Item>HermiteSparse.gi</Item><Item>Hermite elimination for sparse
matrices over &ZZ;<M>/&lt;p^n></M></Item></Row>
</Table>
</Appendix>

<TheIndex/>

</Book>
